{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from asymptotic_significative_interactions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  Directory  already exists\n",
      "Preparing to analyze a data set with 70 variables and 185 samples\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "# This is a simple script that explains how to infer a simplicial complex or a hypergraph\n",
    "# from a presence/absence data table, i.e., a binary matrix of dimension (pun), where p \n",
    "# is the population size (number of random variables) and n is the sample size (number of # data points)\n",
    "\n",
    "##############################\n",
    "# Step 0: Data preparation\n",
    "#\n",
    "# Option to decide if we use the step method (recommended) or the systematic method, which is\n",
    "# longer and does not return a simplicial complex. Use step_method = False for the systematic method.\n",
    "\n",
    "step_method = True \n",
    "\n",
    "# Choose the name of the directory (dir_name) where to save the files and the 'prefix' name of each \n",
    "# created files (data_name)\n",
    "\n",
    "dir_name = 'Directory'\n",
    "data_name = 'Data'\n",
    "\n",
    "# Create target Directory if doesn't exist\n",
    "\n",
    "if not os.path.exists(dir_name):\n",
    "    os.mkdir(dir_name)\n",
    "    print(\"Directory \", dir_name, \" Created \")\n",
    "else:\n",
    "    print(\"Directory \", dir_name, \" already exists\")\n",
    "\n",
    "data_name = os.path.join(dir_name, data_name)\n",
    "\n",
    "# Choose the significance level alpha to use throughout the analysis.\n",
    "alpha = 0.01\n",
    "\n",
    "# Load data\n",
    "data_matrix = np.load('sample_data.npy')\n",
    "data_matrix = data_matrix.astype(np.int64)\n",
    "p,n = data_matrix.shape\n",
    "print(\"Preparing to analyze a data set with \" + str(p) + \" variables and \" + str(n) + \" samples\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2415it [00:00, 12701.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Extract all the unique tables\n",
      "How many different tables :  1090\n",
      "Unique contingency tables saved in file Directory/Data_table_list.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########## First step : Extract all the unique tables\n",
    "print('Step 1: Extract all the unique tables')\n",
    "\n",
    "# Finds all unique tables\n",
    "find_unique_tables(data_matrix, data_name)\n",
    "\n",
    "print(\"Unique contingency tables saved in file \" + data_name + \"_table_list.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1090 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Extract pvalues for all tables with an asymptotic distribution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1090/1090 [00:01<00:00, 715.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting p-values saved in file Directory/Data_asymptotic_pval_dictio.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "######### Second step : Extract all the pvalues with an asymptotic distribution\n",
    "\n",
    "print('Step 2: Extract pvalues for all tables with an asymptotic distribution')\n",
    "\n",
    "pvalues_for_tables(data_name)\n",
    "\n",
    "print(\"Resulting p-values saved in file \" + data_name + \"_asymptotic_pval_dictio.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2415it [00:00, 30907.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3 : Find table for all links and their associated pvalue\n",
      "Results saved in file Directory/Data_asymptotic_pvalues.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "######### Third step : Find table for all links and their associated pvalue\n",
    "\n",
    "print('Step 3 : Find table for all links and their associated pvalue')\n",
    "\n",
    "with open(data_name + '_asymptotic_pval_dictio.json') as jsonfile:\n",
    "    dictio = json.load(jsonfile)\n",
    "    save_pairwise_p_values_phi_dictionary(data_matrix, dictio, data_name + '_asymptotic_pvalues')\n",
    "\n",
    "print(\"Results saved in file \" + data_name + \"_asymptotic_pvalues.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2415it [00:00, 517484.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4 : Generate network and extract edge_list for a given alpha\n",
      "Number of nodes :  66\n",
      "Number of links :  149\n",
      "Edge list saved in file Directory/Data_asymptotic_edge_list_01.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "######### Fourth step : Choose alpha and extract the network\n",
    "\n",
    "print('Step 4 : Generate network and extract edge_list for a given alpha')\n",
    "\n",
    "g = read_pairwise_p_values(data_name + '_asymptotic_pvalues.csv', alpha)\n",
    "\n",
    "nx.write_edgelist(g, data_name + '_asymptotic_edge_list_' + str(alpha)[2:] + '.txt', data=True)\n",
    "\n",
    "print('Number of nodes : ', g.number_of_nodes())\n",
    "print('Number of links : ', g.number_of_edges())\n",
    "print(\"Edge list saved in file \" + data_name + \"_asymptotic_edge_list_\" + str(alpha)[2:] + \".txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5 : Extract all the unique valid cubes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54740it [00:00, 55694.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many different valid cubes :  7372\n",
      "Unique contingency cubes saved inDirectory/Data_cube_list.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "######### Fifth step : Extract all the unique cubes\n",
    "print('Step 5 : Extract all the unique valid cubes')\n",
    "\n",
    "find_unique_cubes(data_matrix, data_name)\n",
    "\n",
    "print(\"Unique contingency cubes saved in\" + data_name + \"_cube_list.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/7372 [00:00<19:26,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6: Extract pvalues for all cubes with an asymptotic distribution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7372/7372 [00:03<00:00, 2124.97it/s]\n"
     ]
    }
   ],
   "source": [
    "######### Sixth step: Extract pvalues for all cubes with an asymptotic distribution\n",
    "\n",
    "print('Step 6: Extract pvalues for all cubes with an asymptotic distribution')\n",
    "\n",
    "pvalues_for_cubes(data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2415it [00:00, 535570.46it/s]\n",
      "97it [00:00, 320100.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7: Find all empty triangles in the network\n",
      "Number of triangles :  96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "######## Seventh step: Find all triangles in the previous network\n",
    "\n",
    "print('Step 7: Find all empty triangles in the network')\n",
    "\n",
    "g = read_pairwise_p_values(data_name + '_asymptotic_pvalues.csv', alpha)\n",
    "\n",
    "save_all_triangles(g, data_name + '_asymptotic_triangles_' + str(alpha)[2:])\n",
    "\n",
    "print('Number of triangles : ', count_triangles_csv(data_name + '_asymptotic_triangles_' + str(alpha)[2:] + '.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "96it [00:00, 65632.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8: Find all the p-values for the triangles under the hypothesis of homogeneity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "######## Eighth step: Find all the p-values for the triangles under the hypothesis of homogeneity\n",
    "\n",
    "print('Step 8: Find all the p-values for the triangles under the hypothesis of homogeneity')\n",
    "\n",
    "with open(data_name + \"_asymptotic_cube_pval_dictio.json\") as jsonfile:\n",
    "    dictio = json.load(jsonfile)\n",
    "    triangles_p_values_tuple_dictionary(data_name + '_asymptotic_triangles_' + str(alpha)[2:] + '.csv', data_name + '_asymptotic_triangles_' + str(alpha)[2:] + '_pvalues.csv', dictio, data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80it [00:00, 175861.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract 2-simplices\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "######## Last step : Exctract all 2-simplices\n",
    "\n",
    "print('Extract 2-simplices')\n",
    "\n",
    "significant_triplet_from_csv(data_name + '_asymptotic_triangles_' + str(alpha)[2:] + '_pvalues.csv', alpha, data_name + '_asymptotic_2-simplices_' + str(alpha)[2:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
